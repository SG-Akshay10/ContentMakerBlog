{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77757c79",
   "metadata": {},
   "source": [
    "# Content Creator Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6a39a",
   "metadata": {},
   "source": [
    "This script creates a web-based application that converts a PDF document into a narrated video. Here's how it works:\n",
    "\n",
    "1. The user uploads a PDF file and a video file through a web interface.\n",
    "2. The application extracts text from the PDF.\n",
    "3. It generates an audio narration of the extracted text.\n",
    "4. The audio is then transcribed to create subtitles.\n",
    "5. Finally, the original video is combined with the generated audio and subtitles.\n",
    "\n",
    "The result is a video that plays the original content while narrating the text from the PDF with synchronized subtitles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07eaa2",
   "metadata": {},
   "source": [
    "## Setup and Usage\n",
    "\n",
    "1. Ensure you have Python and pip installed on your system.\n",
    "2. Save this script as `pdf_to_video_narrator.py`.\n",
    "3. Create a `requirements.txt` file in the same directory with the following content:\n",
    "\n",
    "   ```\n",
    "   PyMuPDF\n",
    "   numpy==1.23.5\n",
    "   pandas\n",
    "   gTTS\n",
    "   openai-whisper\n",
    "   pydub\n",
    "   scikit-video\n",
    "   SoundFile\n",
    "   gradio\n",
    "   ```\n",
    "\n",
    "4. Open a terminal in the directory containing these files and run:\n",
    "\n",
    "   ```\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "5. Install FFmpeg separately, as it's required for video processing.\n",
    "6. Run the script:\n",
    "\n",
    "   ```\n",
    "   python pdf_to_video_narrator.py\n",
    "   ```\n",
    "\n",
    "7. Open the provided URL in your web browser to access the interface.\n",
    "8. Upload a PDF and a video file, then wait for the processing to complete.\n",
    "9. Download or view the resulting narrated video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6622cb",
   "metadata": {},
   "source": [
    "## Code Explanation\n",
    "\n",
    "The script is organized into several sections, each handling a specific part of the process:\n",
    "\n",
    "1. PDF Text Extraction\n",
    "2. Audio Generation and Transcription\n",
    "3. Video Processing\n",
    "4. Main Processing Function\n",
    "5. Gradio Interface\n",
    "\n",
    "Each function is documented with its purpose, inputs, and outputs. The main processing logic is encapsulated in the `process_pdf_and_video()` function, which is called by the Gradio interface.\n",
    "\n",
    "Now, let's dive into the code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa0f31",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a680cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.24.9)\n",
      "Requirement already satisfied: numpy==1.23.5 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: pandas in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: gTTS in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.5.3)\n",
      "Requirement already satisfied: openai-whisper in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (20231117)\n",
      "Requirement already satisfied: pydub in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.25.1)\n",
      "Requirement already satisfied: scikit-video in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.1.11)\n",
      "Requirement already satisfied: SoundFile in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: gradio in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (4.42.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from PyMuPDF->-r requirements.txt (line 1)) (1.24.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gTTS->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gTTS->-r requirements.txt (line 4)) (8.1.7)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: numba in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 5)) (0.60.0)\n",
      "Requirement already satisfied: torch in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: tqdm in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 5)) (4.66.5)\n",
      "Requirement already satisfied: more-itertools in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 5)) (10.4.0)\n",
      "Requirement already satisfied: tiktoken in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pillow in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from scikit-video->-r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: scipy in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from scikit-video->-r requirements.txt (line 7)) (1.14.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from SoundFile->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (4.4.0)\n",
      "Requirement already satisfied: fastapi in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.112.2)\n",
      "Requirement already satisfied: ffmpy in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.24.6)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (6.4.4)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (3.9.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (3.10.7)\n",
      "Requirement already satisfied: packaging in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (24.1)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (2.2.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio->-r requirements.txt (line 9)) (0.30.6)\n",
      "Requirement already satisfied: fsspec in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio-client==1.3.0->gradio->-r requirements.txt (line 9)) (2024.6.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from gradio-client==1.3.0->gradio->-r requirements.txt (line 9)) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 9)) (3.8)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: pycparser in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from cffi>=1.0->SoundFile->-r requirements.txt (line 8)) (2.22)\n",
      "Requirement already satisfied: certifi in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 9)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 9)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 9)) (0.14.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 9)) (3.15.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 9)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 9)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 9)) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from requests<3,>=2.27->gTTS->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (13.8.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from fastapi->gradio->-r requirements.txt (line 9)) (0.38.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from numba->openai-whisper->-r requirements.txt (line 5)) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from tiktoken->openai-whisper->-r requirements.txt (line 5)) (2024.7.24)\n",
      "Requirement already satisfied: sympy in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 5)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper->-r requirements.txt (line 5)) (12.6.68)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (2.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from sympy->torch->openai-whisper->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/akshay/miniconda3/envs/bounty/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c776bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from gtts import gTTS\n",
    "import whisper\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "import skvideo.io\n",
    "import soundfile as sf\n",
    "from subprocess import check_output, STDOUT, CalledProcessError\n",
    "import gradio as gr\n",
    "import shutil\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3adc0b9",
   "metadata": {},
   "source": [
    "## PDF Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0c8cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_extract(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts all text from a PDF file.\n",
    "    \n",
    "    This function opens a PDF file, iterates through all its pages, and extracts the text content.\n",
    "    It's useful for converting PDF documents into plain text for further processing.\n",
    "    \n",
    "    Args:\n",
    "    pdf_path (str): The file path of the PDF from which to extract text.\n",
    "    \n",
    "    Returns:\n",
    "    str: The extracted text from the PDF, with each page separated by a newline.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text() + \"\\n\"\n",
    "    doc.close()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8662bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the extracted text by removing specific formats and correcting spacing.\n",
    "    \n",
    "    This function applies several regex-based cleaning operations to improve the quality of\n",
    "    extracted text. It removes common artifacts from PDF extraction, such as escaped characters,\n",
    "    author names, and unnecessary whitespace.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The text to be cleaned.\n",
    "    \n",
    "    Returns:\n",
    "    str: The cleaned text, ready for further processing or narration.\n",
    "    \"\"\"\n",
    "    # Replace escaped single quotes\n",
    "    text = re.sub(r\"(?i)\\\\\\'\", \"'\", text)\n",
    "    \n",
    "    # Remove authors' names and specific dataset names\n",
    "    text = re.sub(r'\\b[A-Z]+\\s[A-Z]\\s[A-Z]+(\\s-\\s[A-Z]\\s-\\s\\d+)\\b', '', text)\n",
    "    \n",
    "    # Remove section headings\n",
    "    text = re.sub(r'\\b\\d+\\.\\s[A-Z]+\\b', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ea21d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_extract(file_name):\n",
    "    \"\"\"\n",
    "    Extracts and cleans content from a PDF file.\n",
    "    \n",
    "    This function combines the PDF extraction and text cleaning steps into a single operation.\n",
    "    It's the main entry point for processing PDF files in this application.\n",
    "    \n",
    "    Args:\n",
    "    file_name (str): The name of the PDF file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The cleaned content of the PDF, ready for narration.\n",
    "    \"\"\"\n",
    "    text = pdf_extract(file_name)\n",
    "    text = clean_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51163c",
   "metadata": {},
   "source": [
    "## Audio Generation and Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6c84a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(text, language='en', filename='output.mp3'):\n",
    "    \"\"\"\n",
    "    Generate audio from text using gTTS and save it to a file.\n",
    "    \n",
    "    This function converts the given text into speech using Google's Text-to-Speech (gTTS) service.\n",
    "    It's used to create the narration audio for the video.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The text to convert to speech.\n",
    "    language (str): The language of the text (default: 'en' for English).\n",
    "    filename (str): The name of the output audio file (default: 'output.mp3').\n",
    "    \"\"\"\n",
    "    tts = gTTS(text=text, lang=language)\n",
    "    tts.save(filename)\n",
    "    print(f\"Audio saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e46bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(mp3_filename):\n",
    "    \"\"\"\n",
    "    Convert an MP3 file to WAV format for processing.\n",
    "    \n",
    "    This function is used because some audio processing libraries work better with WAV files.\n",
    "    It converts the generated MP3 narration to WAV format for further processing.\n",
    "    \n",
    "    Args:\n",
    "    mp3_filename (str): The name of the MP3 file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The name of the converted WAV file.\n",
    "    \"\"\"\n",
    "    wav_filename = os.path.splitext(mp3_filename)[0] + '.wav'\n",
    "    sound = AudioSegment.from_mp3(mp3_filename)\n",
    "    sound.export(wav_filename, format=\"wav\")\n",
    "    return wav_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a70fd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_filename, model='small', output_dir='.', language='en'):\n",
    "    \"\"\"\n",
    "    Transcribe audio file and generate subtitles.\n",
    "    \n",
    "    This function uses the Whisper model to transcribe the narration audio and generate subtitles.\n",
    "    It's a key step in creating synchronized subtitles for the video.\n",
    "    \n",
    "    Args:\n",
    "    audio_filename (str): The name of the audio file.\n",
    "    model (str): The Whisper model to use (default: 'small').\n",
    "    output_dir (str): The directory to save the output (default: '.').\n",
    "    language (str): The language of the audio (default: 'en' for English).\n",
    "    \n",
    "    Returns:\n",
    "    str: The path of the generated SRT subtitle file.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    audio_filename_wav = convert_to_wav(audio_filename)\n",
    "    \n",
    "    model = whisper.load_model(model)\n",
    "    print(f\"Transcribing {audio_filename}...\")\n",
    "    result = model.transcribe(audio_filename_wav, task='transcribe', language=language)\n",
    "    \n",
    "    srt_path = os.path.join(output_dir, os.path.splitext(os.path.basename(audio_filename))[0] + '.srt')\n",
    "    with open(srt_path, \"w\", encoding=\"utf-8\") as srt_file:\n",
    "        write_srt(iter(result['segments']), srt_file)\n",
    "    \n",
    "    os.remove(audio_filename_wav)  # Clean up the WAV file\n",
    "    return srt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66d3c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_srt(transcript, file):\n",
    "    \"\"\"\n",
    "    Write the transcript to a file in SRT format.\n",
    "    \n",
    "    This function takes the transcription results and formats them into the SubRip (SRT) subtitle format.\n",
    "    SRT is a widely supported format for video subtitles.\n",
    "    \n",
    "    Args:\n",
    "    transcript (iterator): An iterator of transcript segments from the Whisper model.\n",
    "    file (file object): The file to write the SRT content to.\n",
    "    \"\"\"\n",
    "    for i, segment in enumerate(transcript, start=1):\n",
    "        start_time = format_timestamp(segment['start'])\n",
    "        end_time = format_timestamp(segment['end'])\n",
    "        text = segment['text'].replace('-->', '->').strip()\n",
    "        file.write(f\"{i}\\n{start_time} --> {end_time}\\n{text}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4ffc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timestamp(seconds):\n",
    "    \"\"\"\n",
    "    Convert timestamp in seconds to SRT format.\n",
    "    \n",
    "    This helper function formats time in seconds to the HH:MM:SS,mmm format used in SRT files.\n",
    "    \n",
    "    Args:\n",
    "    seconds (float): The timestamp in seconds.\n",
    "    \n",
    "    Returns:\n",
    "    str: The formatted timestamp in SRT format (HH:MM:SS,mmm).\n",
    "    \"\"\"\n",
    "    hours, remainder = divmod(int(seconds), 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec01d2d4",
   "metadata": {},
   "source": [
    "## Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "668837ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_audio_and_subtitles_on_video(video_path, audio_path, subtitle_path, output_path):\n",
    "    \"\"\"\n",
    "    Overlay audio and subtitles on a video.\n",
    "    \n",
    "    This function combines the original video with the generated narration audio and subtitles.\n",
    "    It uses FFmpeg to process the video, which allows for complex video manipulations.\n",
    "    \n",
    "    Args:\n",
    "    video_path (str): Path to the input video file.\n",
    "    audio_path (str): Path to the audio file (narration).\n",
    "    subtitle_path (str): Path to the subtitle file (SRT format).\n",
    "    output_path (str): Path for the output video file.\n",
    "    \"\"\"\n",
    "    # Get video info\n",
    "    video_info = skvideo.io.ffprobe(video_path)\n",
    "    video_duration = float(video_info['video']['@duration'])\n",
    "    \n",
    "    # Read and adjust audio\n",
    "    audio, sample_rate = sf.read(audio_path)\n",
    "    audio_duration = len(audio) / sample_rate\n",
    "    if audio_duration > video_duration:\n",
    "        audio = audio[:int(video_duration * sample_rate)]\n",
    "    elif audio_duration < video_duration:\n",
    "        repeat_times = int(np.ceil(video_duration / audio_duration))\n",
    "        audio = np.tile(audio, repeat_times)[:int(video_duration * sample_rate)]\n",
    "    \n",
    "    # Save adjusted audio\n",
    "    temp_audio_path = 'temp_audio.wav'\n",
    "    sf.write(temp_audio_path, audio, sample_rate)\n",
    "    \n",
    "    # Construct FFmpeg command\n",
    "    cmd = [\n",
    "        'ffmpeg',\n",
    "        '-i', video_path,\n",
    "        '-i', temp_audio_path,\n",
    "        '-vf', f\"subtitles={subtitle_path}:force_style='FontName=Arial,Bold=10,FontSize=12,Alignment=6,MarginV=20'\",\n",
    "        '-c:v', 'libx264',\n",
    "        '-c:a', 'aac',\n",
    "        '-map', '0:v:0',\n",
    "        '-map', '1:a:0',\n",
    "        '-shortest',\n",
    "        output_path\n",
    "    ]\n",
    "    \n",
    "    # Execute FFmpeg command\n",
    "    try:\n",
    "        check_output(cmd, stderr=STDOUT)\n",
    "        print(f\"Video with overlaid audio and synchronized subtitles saved to {output_path}\")\n",
    "    except CalledProcessError as e:\n",
    "        print(f\"Error occurred: {e.output.decode()}\")\n",
    "    \n",
    "    # Clean up temporary files\n",
    "    os.remove(temp_audio_path)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e672fc6f",
   "metadata": {},
   "source": [
    "## Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c06d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_and_video(pdf_file, video_file, output_filename):\n",
    "    \"\"\"\n",
    "    Process a PDF file and a video file to create a narrated video.\n",
    "    \n",
    "    This function orchestrates the entire process of converting a PDF to a narrated video.\n",
    "    It uses a 'data' folder for temporary files and cleans up afterwards.\n",
    "    \n",
    "    Args:\n",
    "    pdf_file (str): Path to the PDF file.\n",
    "    video_file (str): Path to the video file.\n",
    "    \n",
    "    Returns:\n",
    "    str: Path to the output video file.\n",
    "    \"\"\"\n",
    "    # Check if the file extensions are correct\n",
    "    if not pdf_file.lower().endswith('.pdf'):\n",
    "        raise ValueError(\"The provided PDF file does not have a .pdf extension.\")\n",
    "    if not video_file.lower().endswith('.mp4'):\n",
    "        raise ValueError(\"The provided video file does not have a .mp4 extension.\")\n",
    "    \n",
    "    # Create data folder if it doesn't exist\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # Extract content from PDF\n",
    "    content = content_extract(pdf_file)\n",
    "    print(\"\\nContent extracted from pdf file!!\\n\")\n",
    "    \n",
    "    # Generate audio from content\n",
    "    audio_file = os.path.join('data', 'narration.mp3')\n",
    "    generate_audio(content, filename=audio_file)\n",
    "    print(\"\\nAudio file generated!!!\\n\")\n",
    "    \n",
    "    # Transcribe audio to create subtitles\n",
    "    subtitle_file = transcribe_audio(audio_file, output_dir='data')\n",
    "    print(\"\\nAudio transcription completed!!!\\n\")\n",
    "    \n",
    "    # Overlay audio and subtitles on video\n",
    "    output_file = os.path.join('data', f'{output_filename}.mp4')\n",
    "    overlay_audio_and_subtitles_on_video(video_file, audio_file, subtitle_file, output_file)\n",
    "    print(\"\\nVideo Output complete!!\\n\")\n",
    "    \n",
    "    # Move final output to current directory\n",
    "    shutil.move(output_file, f'{output_filename}.mp4')\n",
    "    \n",
    "    # Clean up data folder\n",
    "    for filename in os.listdir('data'):\n",
    "        file_path = os.path.join('data', filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    \n",
    "    return f'{output_filename}.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb7e19",
   "metadata": {},
   "source": [
    "## Create Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "545b600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pdf_file, video_file, output_filename):\n",
    "    try:\n",
    "        output_video_path = process_pdf_and_video(pdf_file, video_file, output_filename)\n",
    "        return output_video_path, \"\"  # Return video path and empty error\n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred: {str(e)}\\n\\nTraceback:\\n{traceback.format_exc()}\"\n",
    "        return None, error_message  # Return None for video and the error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af5866d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=main,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload a PDF\"),\n",
    "        gr.Video(label=\"Upload a Video\"),\n",
    "        gr.Text(label=\"Name of the Output File\", placeholder=\"Enter the filename without extension\")  \n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Video(label=\"Processed Video\"),\n",
    "        gr.Textbox(label=\"Error Output\")\n",
    "    ],\n",
    "    title=\"Video and PDF Processor\",\n",
    "    description=\"Upload a video and a PDF, and get the processed video.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90766b",
   "metadata": {},
   "source": [
    "## Launch the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc3443f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Content extracted from pdf file!!\n",
      "\n",
      "Audio saved as data/narration.mp3\n",
      "\n",
      "Audio file generated!!!\n",
      "\n",
      "Transcribing data/narration.mp3...\n",
      "\n",
      "Audio transcription completed!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea154f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
